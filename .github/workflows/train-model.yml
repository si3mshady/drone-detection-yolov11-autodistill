name: Drone Detection Training

on:
  push:
    paths:
      - 'images/**'
  workflow_dispatch:

jobs:
  train:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install System Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libgl1 \
            libglx-mesa0 \
            libglib2.0-0 \
            libsm6 \
            libxext6 \
            libxrender-dev \
            libgomp1 \
            libgdal-dev \
            ffmpeg \
            libsndfile1
      
      - name: Cache Dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install Python Dependencies
        run: |
          pip install --upgrade pip setuptools wheel
          pip install ultralytics autodistill autodistill-grounded-sam
          pip install roboflow
          pip install opencv-python==4.11.0.86 opencv-contrib-python==4.11.0.86
          pip install scipy==1.15.3 scikit-image==0.25.2 scikit-learn==1.6.1
          pip install pillow==11.2.1 imageio==2.37.0
          pip install transformers==4.53.2 datasets==2.14.4
          pip install huggingface-hub==0.33.4 tokenizers==0.21.2
          pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
          pip install numpy==2.0.2 pandas==2.2.2 matplotlib==3.10.0
          pip install requests==2.32.3 urllib3==2.4.0
          pip install tqdm==4.67.1 packaging==25.0
          pip install wandb==0.21.0
      
      - name: Clean Dataset (Clean Slate Method)
        run: |
          echo "üßπ Clean slate - removing old dataset..."
          rm -rf dataset/
      
      - name: Initialize Dataset Structure
        run: |
          echo "üìÅ Creating dataset directory structure..."
          mkdir -p dataset/train/images dataset/train/labels
          mkdir -p dataset/valid/images dataset/valid/labels
          touch dataset/train/images/.gitkeep
          touch dataset/train/labels/.gitkeep
          touch dataset/valid/images/.gitkeep
          touch dataset/valid/labels/.gitkeep
          echo "‚úÖ Dataset structure created"
      
      - name: Count Images
        run: |
          image_count=$(find images/ -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" 2>/dev/null | wc -l)
          echo "üìä Found $image_count images to process"
          if [ $image_count -eq 0 ]; then
            echo "‚ùå No images found in images/ folder"
            exit 1
          fi
          
          echo "üìã Images found:"
          find images/ -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" | head -10
      
      - name: Autodistill Labeling and YOLO Training
        env:
          WANDB_API_KEY: "632f1185ffe5698beda8749147a1a6772de21e39"
          PYTHONUNBUFFERED: "1"
          HF_HUB_DISABLE_SYMLINKS_WARNING: "1"
        run: |
          python3 << 'EOF'
          import os
          import glob
          import cv2
          from autodistill_grounded_sam import GroundedSAM
          from autodistill.detection import CaptionOntology
          from ultralytics import YOLO
          
          # Verify images exist and are readable
          print('üîç Verifying images...')
          image_files = glob.glob('images/*.jpg') + glob.glob('images/*.jpeg') + glob.glob('images/*.png')
          print(f'Found {len(image_files)} image files: {image_files}')
          
          for img_path in image_files[:3]:
              try:
                  img = cv2.imread(img_path)
                  if img is not None:
                      print(f'‚úÖ {img_path}: {img.shape}')
                  else:
                      print(f'‚ùå {img_path}: Could not load')
              except Exception as e:
                  print(f'‚ùå {img_path}: Error {e}')
          
          print('üîç Auto-labeling images with GroundedSAM...')
          
          # Broad prompts with lower thresholds
          ontology = CaptionOntology({
              'drone': 'drone',
              'quadcopter': 'drone',
              'aircraft': 'drone'
          })
          
          base = GroundedSAM(
              ontology=ontology,
              box_threshold=0.20,
              text_threshold=0.20
          )
          
          base.label(input_folder='./images', output_folder='dataset')
          
          # Enhanced verification with debugging
          print('üìä Checking dataset creation...')
          train_images = glob.glob('dataset/train/images/*')
          train_labels = glob.glob('dataset/train/labels/*')
          valid_images = glob.glob('dataset/valid/images/*')
          valid_labels = glob.glob('dataset/valid/labels/*')
          
          # Move validation data to training if needed
          if len([f for f in train_images if not f.endswith('.gitkeep')]) == 0:
              print('üìÅ Moving validation data to training set...')
              import shutil
              for img_file in valid_images:
                  if not img_file.endswith('.gitkeep'):
                      dst = img_file.replace('/valid/', '/train/')
                      shutil.move(img_file, dst)
                      
              for label_file in valid_labels:
                  if not label_file.endswith('.gitkeep'):
                      dst = label_file.replace('/valid/', '/train/')
                      shutil.move(label_file, dst)
              
              print('‚úÖ Data moved to training directory')
          
          # Recount after potential moving
          train_images = glob.glob('dataset/train/images/*')
          train_labels = glob.glob('dataset/train/labels/*')
          total_labels = len([f for f in train_labels if not f.endswith('.gitkeep')])
          total_images = len([f for f in train_images if not f.endswith('.gitkeep')])
          
          print(f'‚úÖ Final training dataset: {total_labels} labels for {total_images} images')
          
          if total_labels == 0:
              raise RuntimeError('‚ùå No labels created for training')
          
          # Train YOLO model with explicit project/name to control output directory
          print('üéØ Training YOLOv11 for 50 epochs...')
          model = YOLO('yolo11n-seg.pt')
          model.train(
              data='dataset/data.yaml',
              epochs=50,
              imgsz=640,
              batch=16,
              patience=25,
              verbose=True,
              project='runs/segment',
              name='drone_training'
          )
          
          print('üéâ Training completed!')
          
          # Verify training output files exist
          import subprocess
          print('üìÅ Checking training output files...')
          result = subprocess.run(['find', 'runs/', '-name', '*.pt', '-o', '-name', '*.csv', '-o', '-name', '*.png'], 
                                capture_output=True, text=True)
          print('Training output files found:')
          print(result.stdout)
          EOF
      
      - name: Find Training Output Directory
        id: find_output
        run: |
          # Find the actual training directory (handles train, train2, train3, etc.)
          if [ -d "runs/segment/drone_training" ]; then
            TRAIN_DIR="runs/segment/drone_training"
          else
            TRAIN_DIR=$(find runs/segment/ -type d -name "train*" | sort -V | tail -1)
          fi
          
          echo "train_dir=$TRAIN_DIR" >> $GITHUB_OUTPUT
          echo "Found training directory: $TRAIN_DIR"
          
          # List contents for verification
          if [ -d "$TRAIN_DIR" ]; then
            echo "Contents of $TRAIN_DIR:"
            find "$TRAIN_DIR" -type f | head -10
            
            # Check if weights directory exists
            if [ -d "$TRAIN_DIR/weights" ]; then
              echo "Weights directory contents:"
              ls -la "$TRAIN_DIR/weights/"
            else
              echo "‚ö†Ô∏è No weights directory found"
            fi
          else
            echo "‚ùå No training directory found"
            echo "Available directories:"
            find runs/ -type d | head -10
          fi
      
      - name: Upload Trained Model
        uses: actions/upload-artifact@v4
        if: success()
        with:
          name: drone-model-${{ github.sha }}
          path: |
            ${{ steps.find_output.outputs.train_dir }}/weights/best.pt
            ${{ steps.find_output.outputs.train_dir }}/weights/last.pt
          retention-days: 30
      
      - name: Upload Training Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: training-results-${{ github.sha }}
          path: |
            ${{ steps.find_output.outputs.train_dir }}/results.csv
            ${{ steps.find_output.outputs.train_dir }}/results.png
            ${{ steps.find_output.outputs.train_dir }}/confusion_matrix.png
          retention-days: 7
      
      - name: Upload All Training Outputs (Fallback)
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: all-outputs-debug-${{ github.sha }}
          path: |
            runs/**/*.pt
            runs/**/*.csv
            runs/**/*.png
            runs/**/*.yaml
          retention-days: 7
